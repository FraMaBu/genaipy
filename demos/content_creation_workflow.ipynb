{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Creating Content from Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "This notebook demoes how a simple workflow of sequential requests to large language models can be leveraged to create multiple pieces of content from an arbitrary webpage.\n",
    "\n",
    "This workflow consists of three sequential steps:\n",
    "1. Generate a summary of desired webpage\n",
    "2. Structure the summary according to a user-defined outline.\n",
    "3. Create a social media post from structured summary with custom persona.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "This demo uses the OpenAI Chat API and, thus, requires an OpenAI API key.\n",
    "\n",
    "**Disclaimer:**\n",
    "\n",
    "This notebook is strictly for educational purposes. Users should employ it responsibly, ensuring accuracy, respecting privacy and copyright, and avoiding the dissemination of misinformation. Always consider the ethical implications and context of the generated content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Load and parse HTML webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start our workflow, we extract the text content from the desired webpage, focusing on paragraphs and headers, to use downstream. We use the Llama 2 announcement from Meta AI in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Introducing LLaMA  A foundational  65 billion parameter large language model\n",
       "\n",
       "February 24  2023\n",
       "\n",
       "UPDATE  We just launched Llama 2   for more information on the latest see our blog post on Llama 2  \n",
       "\n",
       "As part of Meta s commitment to open science  today we are publicly releasing LLaMA  Large Language Model Meta AI   a state of the art foundational large language model designed to help researchers advance their work in this subfield of AI  Smaller  more performant models such as LLaMA enable others in the research community who don t have access to large amounts of infrastructure to study these models  further democratizing access in this important  fast changing field \n",
       "\n",
       "Training smaller foundation models like LLaMA is desirable in the large language model space because it requires far less computing power and resources to test new approaches  validate others  work  and explore new use cases  Foundation models train on a large set of unlabeled data  which makes them ideal for fine tuning for a variety of tasks  We are making LLaMA available at several sizes  7B  13B  33B  and 65B parameters  and also sharing a LLaMA model card that details how we built the model in keeping with our app"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text from webpage\n",
    "\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "from genaipy.extractors.web import extract_text\n",
    "\n",
    "os.chdir('..') # Change path to root directory\n",
    "\n",
    "URL = \"https://ai.meta.com/blog/large-language-model-llama-meta-ai/\"\n",
    "TAGS = [\"p\", \"h1\"]\n",
    "\n",
    "text = extract_text(url=URL, tags=TAGS)\n",
    "Markdown(text[:1200]) # Display first 1200 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [1/3]: Generate Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step of the workflow, we provide the input text sample to `GPT-3.5-turbo` and request it to generate a 150 words long summary. This step serves as the foundation for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Meta AI has released LLaMA, a large language model designed to assist researchers in the field of AI. The model is smaller and more efficient, making it accessible to researchers who lack extensive resources. LLaMA is available in different sizes and can be fine-tuned for various tasks. Large language models have demonstrated their potential in generating creative text, solving mathematical problems, and answering comprehension questions. However, limited access to these models hinders research progress in understanding their workings and addressing issues like bias and misinformation. LLaMA aims to be versatile and applicable to different use cases. The model is released under a noncommercial license for research purposes, and access is granted on a case-by-case basis. Meta AI encourages collaboration in developing responsible guidelines for large language models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from genaipy.openai_apis.chat import get_chat_response\n",
    "from genaipy.prompts.generate_summaries import build_summary_prompt\n",
    "\n",
    "prompt = build_summary_prompt(text=text, max_words=150)\n",
    "\n",
    "summary = get_chat_response(prompt=prompt, temperature=0.2)\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [2/3]: Structure Summary with Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step of the workflow, we use the generated summary and utilize `GPT-3.5-turbo` to structure it according to a custom outline. Notably, this structured outline is completely customizable to the requirements of the use case (e.g., meeting minutes, reports, etc.).\n",
    "\n",
    "Here, we opted for a basic outline for structuring summaries displayed below. Since the structured summary is in `Markdown`, it can be directly saved and displayed in many text editors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Short Title]\n",
      "\n",
      "## Summary\n",
      "(Exactly 1 sentence long summary of the main topic and objective.)\n",
      "\n",
      "## Key points \n",
      "(bulleted list of 3-5 main points.)\n",
      "- [Key insight 1]\n",
      "- [Key insight 2]\n",
      "- [Key insight 3]\n",
      "- ... (only if needed)\n",
      "\n",
      "## Key concepts\n",
      "(bulleted list of exactly 3-5 main concepts and entities.)\n",
      "- [Key concept/entity 1]\n",
      "- [Key concept/entity 2]\n",
      "- [Key concept/entity 3]\n",
      "- ... (only if needed)\n"
     ]
    }
   ],
   "source": [
    "# Load structured outline\n",
    "\n",
    "from genaipy.outlines.basic_summary_outline import BASIC_SUMMARY_OUTLINE\n",
    "\n",
    "tpl = BASIC_SUMMARY_OUTLINE.strip()\n",
    "print(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "# Meta AI's LLaMA: A Versatile Language Model for AI Research\n",
       "\n",
       "## Summary\n",
       "Meta AI has developed LLaMA, a smaller and more efficient language model, to assist researchers in the field of AI by providing access to large language models for various tasks, while addressing issues like bias and misinformation.\n",
       "\n",
       "## Key points\n",
       "- LLaMA is a large language model designed to assist researchers in AI with limited resources.\n",
       "- The model is smaller and more efficient, making it accessible to a wider range of researchers.\n",
       "- LLaMA can be fine-tuned for different tasks and is available in various sizes.\n",
       "- Large language models have shown potential in generating creative text, solving mathematical problems, and answering comprehension questions.\n",
       "- Limited access to these models hampers research progress in understanding their workings and addressing issues like bias and misinformation.\n",
       "\n",
       "## Key concepts\n",
       "- LLaMA: A language model developed by Meta AI to assist researchers in AI.\n",
       "- Fine-tuning: The process of adapting a pre-trained language model for specific tasks.\n",
       "- Bias and misinformation: Issues that need to be addressed in large language models.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate structured summary\n",
    "\n",
    "from genaipy.prompts.style_texts import build_style_prompt\n",
    "\n",
    "style_prompt = build_style_prompt(text=summary, tpl=tpl)\n",
    "\n",
    "styled_summary = get_chat_response(prompt=style_prompt, temperature=0) \n",
    "Markdown(styled_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [3/3]: Generate Social Media Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of the workflow, we generate a social media post from the structured summary using `GPT-4-turbo`. \n",
    "Notably, we set a custom role for the LLM via the system message to tailor the style and tone of the post.\n",
    "\n",
    "In this case, we set the LLM's role to a  professional content creator on Linkedin excelling at communicating complex AI topics in a simple way. Feel free to change the system message below, to explore different types of social media posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are an expert content creator on LinkedIn. You excell at communicating complex topics in Generative AI in a simple and professional way."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define custom role\n",
    "\n",
    "system_message = \"You are an expert content creator on LinkedIn. You excell at communicating complex topics in Generative AI in a simple and professional way.\"\n",
    "Markdown(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "🚀 Exciting News from Meta AI: Introducing LLaMA 🌟\n",
       "\n",
       "As an AI enthusiast, I'm thrilled to share that Meta AI has launched a game-changer: LLaMA, a language model that's not just powerful but also efficient and accessible!\n",
       "\n",
       "🔍 **Why LLaMA Stands Out:**\n",
       "- Tailored for researchers with limited resources, LLaMA is here to democratize AI research.\n",
       "- It's a versatile tool, ready to be fine-tuned for a spectrum of tasks.\n",
       "- Expect LLaMA in various sizes, catering to different research needs.\n",
       "\n",
       "💡 **Impact on AI Research:**\n",
       "- LLaMA's efficiency could revolutionize creative text generation, complex problem-solving, and comprehension tasks.\n",
       "- It's a step towards overcoming research barriers in understanding and improving language models, especially in tackling bias and misinformation.\n",
       "\n",
       "I'm eager to see how LLaMA will shape the future of AI research. Let's discuss how this innovation can unlock new possibilities! #AILaMA #MetaAI #LanguageModels #AIResearch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate LinkedIn post\n",
    "\n",
    "from genaipy.prompts.generate_posts import build_post_prompt\n",
    "\n",
    "generate_prompt = build_post_prompt(text=styled_summary, max_words=150)\n",
    "\n",
    "post = get_chat_response(\n",
    "    prompt=generate_prompt,\n",
    "    sys_message=system_message,\n",
    "    temperature=0.5,\n",
    "    model=\"gpt-4-1106-preview\"\n",
    "    )\n",
    "\n",
    "Markdown(post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
