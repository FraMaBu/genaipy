{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a helpful assistant.'}\n"
     ]
    }
   ],
   "source": [
    "role = \"system\"\n",
    "content = \"You are a helpful assistant.\"\n",
    "\n",
    "def construct_chat_message(role: str, content: str) -> dict:\n",
    "    if role not in (\"system\", \"user\", \"assistant\"):\n",
    "        raise ValueError(\"Invalid role, must be 'system', 'user' or 'assistant'.\")\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "print(construct_chat_message(role, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed after 3 retries. Last error message: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000019C9AD85750>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Optional, Any\n",
    "import openai\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"}\n",
    "]\n",
    "\n",
    "def request_chat_completion(messages: dict, model: str = \"gpt-3.5-turbo\", max_retries: int = 3, **kwargs: Any) -> Optional[dict]:\n",
    "\n",
    "    last_error_msg = \"\"\n",
    "    for _ in range(max_retries):\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=model, messages=messages, **kwargs\n",
    "            )\n",
    "            return completion\n",
    "        except Exception as e:\n",
    "            last_error_msg = str(e)\n",
    "            sleep(3)\n",
    "\n",
    "    logging.error(f\"Failed after {max_retries} retries. Last error message: {last_error_msg}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "print(request_chat_completion(messages=messages, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Who is Socrates?'}]\n",
      "Failed after 3 retries. Last error message:\n",
      "Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001A2F96FB790>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "Failed to retrieve completion from OpenAI Chat API. 'NoneType' object has no attribute 'choices'\n"
     ]
    }
   ],
   "source": [
    "sys_message = \"\"\n",
    "prompt = \"Who is Socrates?\"\n",
    "\n",
    "messages = []\n",
    "\n",
    "if sys_message:\n",
    "    messages.append(construct_chat_message(\"system\", sys_message))\n",
    "\n",
    "messages.append(construct_chat_message(\"user\", prompt))\n",
    "\n",
    "print(messages)\n",
    "\n",
    "completion = request_chat_completion(messages)\n",
    "\n",
    "try:\n",
    "    print(completion.choices[0].message[\"content\"])\n",
    "except AttributeError as e:\n",
    "    print(f\"Failed to retrieve completion from OpenAI Chat API: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr, Socrates be an ancient Greek philosopher, matey! He be known fer his deep thinkin' and his fancy way o' questionin' everything. He be one o' the founders o' Western philosophy, teachin' many famous lads like Plato and Xenophon. Socrates be a wise ol' soul who be sailin' the seas o' knowledge!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any\n",
    "import openai\n",
    "\n",
    "sys_message = \"You are a helpful assistant answering like a pirate\"\n",
    "prompt = \"Who is Socrates?\"\n",
    "\n",
    "def get_chat_response(prompt: str, sys_message: str = \"\", model: str = \"gpt-3.5-turbo\", **kwargs: Any) -> str:\n",
    "    \"\"\"\n",
    "    Generates a chatbot response using OpenAI's Chat API.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The message from the user.\n",
    "        sys_message (str, optional): A system message for the LLM. Defaults to an empty string.\n",
    "        model (str, optional): The name of the OpenAI model to use. Defaults to \"gpt-3.5-turbo\".\n",
    "        **kwargs: Additional keyword arguments to pass to the `request_chat_completion` function.\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: The content of the LLM's response or None if an error occurs.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Raised when `request_chat_completion` returns `None`.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if sys_message:\n",
    "        messages.append(construct_chat_message(\"system\", sys_message))\n",
    "        \n",
    "    messages.append(construct_chat_message(\"user\", prompt))\n",
    "    completion = request_chat_completion(messages, model=model, **kwargs)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Token usage: %s\", completion['usage'])\n",
    "        return completion.choices[0].message[\"content\"]\n",
    "    except TypeError as e:\n",
    "        logging.error(\"Failed to retrieve completion from OpenAI Chat API: %s\", {e})\n",
    "        raise\n",
    "\n",
    "print(get_chat_response(prompt, sys_message, temperature = 0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
