{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instructions:\n",
      "Your task is to generate a summary of the text sample.\n",
      "Summarize the text sample provided below, delimited by triple backticks, in at most {max_words} words.\n",
      "\n",
      "Text sample:\n",
      "```{text}```\n",
      "\n",
      "Summarized text:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load prompt template\n",
    "from prompts.summary_prompt import SUMMARY_PROMPT_TEMPLATE\n",
    "\n",
    "prompt_tpl = SUMMARY_PROMPT_TEMPLATE\n",
    "print(prompt_tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search in the Context of LLMs  Semantic Search in the LLM Space: Enhancing Search Capabilities with Language Models Semantic search has revolutionized information retrieval and retrieval augmented generation (RAG) techniques. By leveraging the power of language models and text embeddings, semantic search enables more accurate and efficient document retrieval. In this article, we delve into the world of LLM-enabled semantic search, exploring how it works, its benefits, and the underlying technologies driving its success.  Understanding Semantic Search Semantic search goes beyond traditional keyword-based search methods by considering the meaning and intent behind a user’s query. It leverages text embeddings, which are multi-dimensional numerical representations of “meaning” generated by language models. These embeddings capture the semantic relationships between words and phrases, allowing for more nuanced and context-aware document retrieval.  To put it simply, semantic search involves representing both user queries and documents in an embedding space. By mapping the semantics of text onto this multi-dimensional space, it becomes possible to perform vector searches to find documents that align closely with the user’s query intent. The result is faster, more accurate search results, improving the overall user experience.  The Role of Embeddings in Semantic Search Embeddings play a crucial role in enabling semantic search. These numerical representations capture the semantic meaning of text by encoding it into vectors consisting of hundreds to thousands of numbers. One popular model for generating such embeddings is OpenAI’s text-embedding-ada-002. However, there are other options available, including open-source alternatives, albeit with varying degrees of power and ease of use.  A good embedding model where queries are sent for retrieval and indexing Illustration by  Roman Grebennikov To gain a better understanding of embeddings, imagine a three-dimensional space where the location of “Obama” is close to “president,” and “Illinois” is close to “Chicago.” Comparing documents like “Obama speaks to the media in Illinois” and “The president greets the press in Chicago” in this space would yield a high degree of semantic similarity. On the other hand, comparing the first document with something like “The quick brown fox jumped over the whatever” would result in a low semantic similarity score. By representing text semantics in this multi-dimensional space, semantic search algorithms can efficiently and accurately identify relevant documents.  The Components of Semantic Search Semantic search systems rely on three key components: embedding models, vector indexes, and similarity search algorithms.  Embedding Models The choice of an embedding model is crucial for the effectiveness of semantic search. Models like BERT, sentence-transformers, and LLMs (Large Language Models) are commonly used to generate text embeddings. However, there are important considerations to keep in mind when selecting an embedding model:  Performance Comparison: Are paid models from companies like OpenAI and Cohere superior to open-source alternatives? Multilingual Capabilities: How well do these models handle multiple languages? Are there advantages to using large-scale models with 1B+ parameters? Sparse vs. Dense Retrieval: Dense retrieval techniques, relying on embeddings, are popular in semantic search. But how do they compare to newer sparse approaches like SPLADEv2 and ELSER? These questions highlight the need for careful evaluation and consideration when choosing an embedding model for semantic search applications.  Vector Indexes Vector indexes serve as the backbone of semantic search systems. These indexes store the embeddings of documents, allowing for efficient and fast retrieval during the search process. By leveraging vector-based indexing techniques, semantic search algorithms can quickly locate documents with similar semantic representations to the user’s query.  Similarity Search The final piece of the puzzle is the similarity search algorithm. Given a user query’s semantic representation, this algorithm identifies the most relevant documents based on their proximity in the embedding space. By calculating the similarity scores between query embeddings and document embeddings, semantic search systems can rank and present the most suitable documents to the user.  Advantages and Applications of LLM-enabled Semantic Search LLM-enabled semantic search offers several advantages over traditional search methods. Some of the key benefits include:  Enhanced Precision: By understanding the meaning and intent behind queries, semantic search provides more precise and contextually relevant search results. Improved Efficiency: Leveraging the power of LLMs and text embeddings allows for faster retrieval of relevant documents, reducing search times. Multilingual Support: LLMs are capable of handling multiple languages, making semantic search effective across diverse linguistic contexts. Versatility: Semantic search can be applied to various domains, including web search, document retrieval, question answering systems, and chatbots, among others. Conclusion Semantic search, empowered by LLMs and text embeddings, has revolutionized the way we retrieve information. By incorporating the semantic meaning of text into the search process, we can achieve more accurate and efficient document retrieval. However, choosing the right embedding model and understanding the underlying technologies are essential for successful implementation. As LLMs continue to evolve, the future of semantic search holds even greater potential for advancing the field of information retrieval and natural language understanding.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve article to summarize\n",
    "\n",
    "text = input(\"Please copy article here:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instructions:\n",
      "Your task is to generate a summary of the text sample.\n",
      "Summarize the text sample provided below, delimited by triple backticks, in at most 150 words.\n",
      "\n",
      "Text sample:\n",
      "```Semantic Search in the Context of LLMs  Semantic Search in the LLM Space: Enhancing Search Capabilities with Language Models Semantic search has revolutionized information retrieval and retrieval augmented generation (RAG) techniques. By leveraging the power of language models and text embeddings, semantic search enables more accurate and efficient document retrieval. In this article, we delve into the world of LLM-enabled semantic search, exploring how it works, its benefits, and the underlying technologies driving its success.  Understanding Semantic Search Semantic search goes beyond traditional keyword-based search methods by considering the meaning and intent behind a user’s query. It leverages text embeddings, which are multi-dimensional numerical representations of “meaning” generated by language models. These embeddings capture the semantic relationships between words and phrases, allowing for more nuanced and context-aware document retrieval.  To put it simply, semantic search involves representing both user queries and documents in an embedding space. By mapping the semantics of text onto this multi-dimensional space, it becomes possible to perform vector searches to find documents that align closely with the user’s query intent. The result is faster, more accurate search results, improving the overall user experience.  The Role of Embeddings in Semantic Search Embeddings play a crucial role in enabling semantic search. These numerical representations capture the semantic meaning of text by encoding it into vectors consisting of hundreds to thousands of numbers. One popular model for generating such embeddings is OpenAI’s text-embedding-ada-002. However, there are other options available, including open-source alternatives, albeit with varying degrees of power and ease of use.  A good embedding model where queries are sent for retrieval and indexing Illustration by  Roman Grebennikov To gain a better understanding of embeddings, imagine a three-dimensional space where the location of “Obama” is close to “president,” and “Illinois” is close to “Chicago.” Comparing documents like “Obama speaks to the media in Illinois” and “The president greets the press in Chicago” in this space would yield a high degree of semantic similarity. On the other hand, comparing the first document with something like “The quick brown fox jumped over the whatever” would result in a low semantic similarity score. By representing text semantics in this multi-dimensional space, semantic search algorithms can efficiently and accurately identify relevant documents.  The Components of Semantic Search Semantic search systems rely on three key components: embedding models, vector indexes, and similarity search algorithms.  Embedding Models The choice of an embedding model is crucial for the effectiveness of semantic search. Models like BERT, sentence-transformers, and LLMs (Large Language Models) are commonly used to generate text embeddings. However, there are important considerations to keep in mind when selecting an embedding model:  Performance Comparison: Are paid models from companies like OpenAI and Cohere superior to open-source alternatives? Multilingual Capabilities: How well do these models handle multiple languages? Are there advantages to using large-scale models with 1B+ parameters? Sparse vs. Dense Retrieval: Dense retrieval techniques, relying on embeddings, are popular in semantic search. But how do they compare to newer sparse approaches like SPLADEv2 and ELSER? These questions highlight the need for careful evaluation and consideration when choosing an embedding model for semantic search applications.  Vector Indexes Vector indexes serve as the backbone of semantic search systems. These indexes store the embeddings of documents, allowing for efficient and fast retrieval during the search process. By leveraging vector-based indexing techniques, semantic search algorithms can quickly locate documents with similar semantic representations to the user’s query.  Similarity Search The final piece of the puzzle is the similarity search algorithm. Given a user query’s semantic representation, this algorithm identifies the most relevant documents based on their proximity in the embedding space. By calculating the similarity scores between query embeddings and document embeddings, semantic search systems can rank and present the most suitable documents to the user.  Advantages and Applications of LLM-enabled Semantic Search LLM-enabled semantic search offers several advantages over traditional search methods. Some of the key benefits include:  Enhanced Precision: By understanding the meaning and intent behind queries, semantic search provides more precise and contextually relevant search results. Improved Efficiency: Leveraging the power of LLMs and text embeddings allows for faster retrieval of relevant documents, reducing search times. Multilingual Support: LLMs are capable of handling multiple languages, making semantic search effective across diverse linguistic contexts. Versatility: Semantic search can be applied to various domains, including web search, document retrieval, question answering systems, and chatbots, among others. Conclusion Semantic search, empowered by LLMs and text embeddings, has revolutionized the way we retrieve information. By incorporating the semantic meaning of text into the search process, we can achieve more accurate and efficient document retrieval. However, choosing the right embedding model and understanding the underlying technologies are essential for successful implementation. As LLMs continue to evolve, the future of semantic search holds even greater potential for advancing the field of information retrieval and natural language understanding.```\n",
      "\n",
      "Summarized text:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build prompt\n",
    "from prompts.summary_prompt import build_summary_prompt \n",
    "\n",
    "prompt = build_summary_prompt(text=text, max_words=150)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Semantic search, powered by language models and text embeddings, has transformed information retrieval. It goes beyond keyword-based search by considering the meaning and intent behind a user's query. Text embeddings, which capture semantic relationships between words and phrases, enable more nuanced and context-aware document retrieval. Embeddings play a crucial role in semantic search by encoding the semantic meaning of text into numerical vectors. The choice of an embedding model is important, considering factors like performance, multilingual capabilities, and retrieval techniques. Vector indexes store document embeddings for efficient retrieval, and similarity search algorithms rank relevant documents based on their proximity to the query's semantic representation. LLM-enabled semantic search offers enhanced precision, improved efficiency, multilingual support, and versatility in various domains. Successful implementation requires selecting the right embedding model and understanding the underlying technologies. The future of semantic search holds great potential for advancing information retrieval and natural language understanding."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai_apis.chat import get_chat_response\n",
    "from IPython.display import Markdown \n",
    "\n",
    "summary = get_chat_response(prompt=prompt, temperature=0.2)\n",
    "\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text:\n",
      "{text}\n",
      "\n",
      "Instructions:\n",
      "Transform the provided text into the provided outline enclosed by triple back ticks.\n",
      "\n",
      "Outline:\n",
      "```{tpl}```\n",
      "\n",
      "Provide your response in {output_type}. Only return the final, filled outline in your response.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts.style_text_prompt import STYLE_TEXT_PROMPT_TEMPLATE\n",
    "\n",
    "style_prompt_template = STYLE_TEXT_PROMPT_TEMPLATE\n",
    "print(style_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Short Title]\n",
      "\n",
      "## Summary\n",
      "(1-2 sentences long summary of the main topic and objective.)\n",
      "\n",
      "## Key points \n",
      "(bulleted list of 3-5 main points.)\n",
      "- [Key insight 1]\n",
      "- [Key insight 2]\n",
      "- [Key insight 3]\n",
      "- ... (only if needed)\n",
      "\n",
      "## Key concepts\n",
      "(bulleted list of exactly 3-5 main concepts and entities.)\n",
      "- [Key concept/entity 1]\n",
      "- [Key concept/entity 2]\n",
      "- [Key concept/entity 3]\n",
      "- ... (only if needed)\n"
     ]
    }
   ],
   "source": [
    "# Load layout template\n",
    "from outlines.basic_summary_outline import BASIC_SUMMARY_OUTLINE\n",
    "\n",
    "tpl = BASIC_SUMMARY_OUTLINE.strip()\n",
    "print(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text:\n",
      "Semantic search, powered by language models and text embeddings, has transformed information retrieval. It goes beyond keyword-based search by considering the meaning and intent behind a user's query. Text embeddings, which capture semantic relationships between words and phrases, enable more nuanced and context-aware document retrieval. Embeddings play a crucial role in semantic search by encoding the semantic meaning of text into numerical vectors. The choice of an embedding model is important, considering factors like performance, multilingual capabilities, and retrieval techniques. Vector indexes store document embeddings for efficient retrieval, and similarity search algorithms rank relevant documents based on their proximity to the query's semantic representation. LLM-enabled semantic search offers enhanced precision, improved efficiency, multilingual support, and versatility in various domains. Successful implementation requires selecting the right embedding model and understanding the underlying technologies. The future of semantic search holds great potential for advancing information retrieval and natural language understanding.\n",
      "\n",
      "Instructions:\n",
      "Transform the provided text into the provided outline enclosed by triple back ticks.\n",
      "\n",
      "Outline:\n",
      "```# [Short Title]\n",
      "\n",
      "## Summary\n",
      "(1-2 sentences long summary of the main topic and objective.)\n",
      "\n",
      "## Key points \n",
      "(bulleted list of 3-5 main points.)\n",
      "- [Key insight 1]\n",
      "- [Key insight 2]\n",
      "- [Key insight 3]\n",
      "- ... (only if needed)\n",
      "\n",
      "## Key concepts\n",
      "(bulleted list of exactly 3-5 main concepts and entities.)\n",
      "- [Key concept/entity 1]\n",
      "- [Key concept/entity 2]\n",
      "- [Key concept/entity 3]\n",
      "- ... (only if needed)```\n",
      "\n",
      "Provide your response in markdown. Only return the final, filled outline in your response.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build style prompt\n",
    "from prompts.style_text_prompt import build_style_text_prompt\n",
    "\n",
    "style_prompt = build_style_text_prompt(text=summary, tpl=tpl)\n",
    "print(style_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```# Semantic Search: Transforming Information Retrieval\n",
       "\n",
       "## Summary\n",
       "Semantic search, powered by language models and text embeddings, goes beyond keyword-based search by considering the meaning and intent behind a user's query. It enables more nuanced and context-aware document retrieval, offering enhanced precision, improved efficiency, multilingual support, and versatility in various domains.\n",
       "\n",
       "## Key points\n",
       "- Semantic search considers the meaning and intent behind a user's query, going beyond keyword-based search.\n",
       "- Text embeddings capture semantic relationships between words and phrases, enabling more nuanced and context-aware document retrieval.\n",
       "- Embeddings encode the semantic meaning of text into numerical vectors, playing a crucial role in semantic search.\n",
       "- Vector indexes store document embeddings for efficient retrieval, while similarity search algorithms rank relevant documents based on their proximity to the query's semantic representation.\n",
       "\n",
       "## Key concepts\n",
       "- Semantic search: Information retrieval approach that considers the meaning and intent behind a user's query.\n",
       "- Text embeddings: Numerical vectors that capture semantic relationships between words and phrases.\n",
       "- Vector indexes: Storage mechanism for document embeddings, enabling efficient retrieval.```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#styled_summary = get_chat_response(prompt=style_prompt, temperature=0) \n",
    "Markdown(styled_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text sample:\n",
      "```{text}```\n",
      "\n",
      "Instructions:\n",
      "Your task is to generate an engaging {platform} post about the provided text sample delimited by triple back ticks.\n",
      "\n",
      "Guidelines:\n",
      "- Clearly structure the post by using headings, paragraphs, and bulleted lists. \n",
      "- Write the post in first person.\n",
      "- Limit your post to at most {max_words} words.\n",
      "\n",
      " Only return the engaging post in your response and nothing else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load prompt template\n",
    "from prompts.generate_post_prompt import GENERATE_POST_PROMPT_TEMPLATE\n",
    "\n",
    "generate_prompt_tpl = GENERATE_POST_PROMPT_TEMPLATE\n",
    "print(generate_prompt_tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text sample:\n",
      "``````# Semantic Search: Transforming Information Retrieval\n",
      "\n",
      "## Summary\n",
      "Semantic search, powered by language models and text embeddings, goes beyond keyword-based search by considering the meaning and intent behind a user's query. It enables more nuanced and context-aware document retrieval, offering enhanced precision, improved efficiency, multilingual support, and versatility in various domains.\n",
      "\n",
      "## Key points\n",
      "- Semantic search considers the meaning and intent behind a user's query, going beyond keyword-based search.\n",
      "- Text embeddings capture semantic relationships between words and phrases, enabling more nuanced and context-aware document retrieval.\n",
      "- Embeddings encode the semantic meaning of text into numerical vectors, playing a crucial role in semantic search.\n",
      "- Vector indexes store document embeddings for efficient retrieval, while similarity search algorithms rank relevant documents based on their proximity to the query's semantic representation.\n",
      "\n",
      "## Key concepts\n",
      "- Semantic search: Information retrieval approach that considers the meaning and intent behind a user's query.\n",
      "- Text embeddings: Numerical vectors that capture semantic relationships between words and phrases.\n",
      "- Vector indexes: Storage mechanism for document embeddings, enabling efficient retrieval.``````\n",
      "\n",
      "Instructions:\n",
      "Your task is to generate an engaging LinkedIn post about the provided text sample delimited by triple back ticks.\n",
      "\n",
      "Guidelines:\n",
      "- Clearly structure the post by using headings, paragraphs, and bulleted lists. \n",
      "- Write the post in first person.\n",
      "- Limit your post to at most 150 words.\n",
      "\n",
      " Only return the engaging post in your response and nothing else.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from prompts.generate_post_prompt import build_generate_post_prompt\n",
    "\n",
    "generate_prompt = build_generate_post_prompt(text=styled_summary, max_words=150)\n",
    "print(generate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Just dived into the fascinating world of #SemanticSearch, an information retrieval approach that goes beyond keyword-based search. 🚀\n",
       "\n",
       "Key Insights:\n",
       "- Semantic search considers the meaning and intent behind a user's query, offering enhanced precision and improved efficiency. 🎯\n",
       "- Text embeddings are the stars of the show, capturing semantic relationships between words and phrases. 🌟\n",
       "- Vector indexes store document embeddings for efficient retrieval. A game-changer for data storage! 💽\n",
       "\n",
       "In a world where data is king, semantic search offers multilingual support and versatility across various domains. Exciting times ahead! 💡 #InformationRetrieval #TextEmbeddings #DataScience"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = get_chat_response(prompt=generate_prompt, temperature=0.5, model=\"gpt-4\") \n",
    "Markdown(post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
